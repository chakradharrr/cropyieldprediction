{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c489ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9db6db0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 1s 4ms/step - loss: 5.9314\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.7403\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.5539\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.4991\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.5095\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.4626\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.4311\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3.4074\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.4075\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.3997\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.3879\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3.3699\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.3617\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.3333\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.3628\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.3643\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.3757\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.3480\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.3592\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.3237\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.3169\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.3077\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.3181\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.3024\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.2911\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.2857\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2763\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.2959\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.2701\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.2775\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.2616\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2909\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2633\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2397\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.2515\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.2434\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2273\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2187\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2136\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2397\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2369\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2148\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.1947\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2153\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2147\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2016\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.1887\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2122\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2087\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2051\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.1824\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1710\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2083\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2055\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1790\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2067\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1958\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1920\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1903\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.1866\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1697\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1733\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1789\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1835\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1395\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1544\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1702\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1604\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1174\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1069\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.0977\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1024\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1225\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1578\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2634\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.3091\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2795\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2012\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.2303\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1890\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1989\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1782\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.1557\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1573\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.1397\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1587\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1237\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1352\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1537\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1409\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1325\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1665\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1402\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.1509\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1350\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.1096\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.0701\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.0878\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.0613\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3.0763\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "R2 Score: 0.18404146771873287\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "data=pd.read_excel(\"final catgry.xlsx\")\n",
    "x=data.drop('Yield (Bales/Hectare)',axis=1).values\n",
    "x\n",
    "y=data['Yield (Bales/Hectare)'].values\n",
    "y\n",
    "# Select relevant features and target variable\n",
    "features =data.drop(['Yield (Bales/Hectare)','Year_2014 - 2015', 'Year_2015 - 2016', 'Year_2016 - 2017','Year_2017 - 2018', 'Year_2018 - 2019', 'Year_2019 - 2020',],axis=1)\n",
    "target = data['Yield (Bales/Hectare)']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Reshape the input data to (samples, timesteps, features)\n",
    "n_samples = X_train.shape[0]\n",
    "n_timesteps = 1\n",
    "n_features = X_train.shape[1]\n",
    "X_train = X_train.reshape((n_samples, n_timesteps, n_features))\n",
    "X_test = X_test.reshape((X_test.shape[0], n_timesteps, n_features))\n",
    "\n",
    "# Define the RNN model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(64, input_shape=(n_timesteps, n_features)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "065f7a9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0\\\\t'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Select relevant features and target variable\u001b[39;00m\n\u001b[0;32m     14\u001b[0m target \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYield (Bales/Hectare)\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 15\u001b[0m features \u001b[38;5;241m=\u001b[39m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0.1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0\t\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYield (Bales/Hectare)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear_2014 - 2015\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear_2015 - 2016\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear_2016 - 2017\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear_2017 - 2018\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear_2018 - 2019\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear_2019 - 2020\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Split data into train and test sets\u001b[39;00m\n\u001b[0;32m     19\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(features, target, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m19\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4957\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4809\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   4810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4811\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4818\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4819\u001b[0m ):\n\u001b[0;32m   4820\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4821\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4822\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4955\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4956\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4963\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4964\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4965\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6661\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6661\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6662\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Unnamed: 0\\\\t'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#linear regression\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "data=pd.read_excel(\"final catgry.xlsx\")\n",
    "x=data.drop('Yield (Bales/Hectare)',axis=1).values\n",
    "x\n",
    "y=data['Yield (Bales/Hectare)'].values\n",
    "y\n",
    "# Select relevant features and target variable\n",
    "target = data['Yield (Bales/Hectare)']\n",
    "features =data.drop(['Unnamed: 0.1','Unnamed: 0\t','Yield (Bales/Hectare)','Year_2014 - 2015', 'Year_2015 - 2016', 'Year_2016 - 2017','Year_2017 - 2018', 'Year_2018 - 2019', 'Year_2019 - 2020',],axis=1)\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=19)\n",
    "\n",
    "# Initialize and train the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dd0c22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.04704271914853986\n"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "data=pd.read_excel(\"final catgry.xlsx\")\n",
    "x=data.drop('Yield (Bales/Hectare)',axis=1).values\n",
    "x\n",
    "y=data['Yield (Bales/Hectare)'].values\n",
    "y\n",
    "# Select relevant features and target variable\n",
    "features =data.drop(['Yield (Bales/Hectare)','Year_2014 - 2015', 'Year_2015 - 2016', 'Year_2016 - 2017','Year_2017 - 2018', 'Year_2018 - 2019', 'Year_2019 - 2020',],axis=1)\n",
    "target = data['Yield (Bales/Hectare)']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the SVR model\n",
    "model = SVR(kernel='rbf')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3567e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.8420630767584057\n"
     ]
    }
   ],
   "source": [
    "#xgboost\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "data=pd.read_excel(\"final catgry.xlsx\")\n",
    "x=data.drop('Yield (Bales/Hectare)',axis=1).values\n",
    "x\n",
    "y=data['Yield (Bales/Hectare)'].values\n",
    "y\n",
    "# Select relevant features and target variable\n",
    "features =data.drop(['Yield (Bales/Hectare)','Year_2014 - 2015', 'Year_2015 - 2016', 'Year_2016 - 2017','Year_2017 - 2018', 'Year_2018 - 2019', 'Year_2019 - 2020',],axis=1)\n",
    "target = data['Yield (Bales/Hectare)']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ace8870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 1s 3ms/step - loss: 6.7266\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.8328\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.6204\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.0302\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.7770\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.6667\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.6020\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5407\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4965\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4745\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4450\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4205\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3951\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3864\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3639\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3539\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3475\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3323\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3259\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3156\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2996\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2985\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3009\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2771\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2754\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2713\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2674\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2620\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2614\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2565\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2503\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2476\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2444\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2411\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2356\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2329\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2286\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2246\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2219\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2164\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2214\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2192\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2212\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2154\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2138\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2082\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1958\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1966\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1976\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1947\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2024\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2051\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2205\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1918\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1985\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1910\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1850\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1834\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1813\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1777\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1785\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1789\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1742\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1739\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1683\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1727\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1658\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1655\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1677\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1629\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1542\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1609\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1630\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1565\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1602\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1559\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1627\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1608\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1535\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1716\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1523\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1515\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1550\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1572\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1500\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1507\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1403\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1573\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1582\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1475\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1434\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1376\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1390\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1473\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1437\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1440\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1328\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1358\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1306\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1322\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "R2 Score: 0.8239853725308988\n"
     ]
    }
   ],
   "source": [
    "#neural network model using the Keras library \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "data=pd.read_excel(\"final catgry.xlsx\")\n",
    "x=data.drop('Yield (Bales/Hectare)',axis=1).values\n",
    "x\n",
    "y=data['Yield (Bales/Hectare)'].values\n",
    "y\n",
    "# Select relevant features and target variable\n",
    "features =data.drop(['Yield (Bales/Hectare)','Year_2014 - 2015', 'Year_2015 - 2016', 'Year_2016 - 2017','Year_2017 - 2018', 'Year_2018 - 2019', 'Year_2019 - 2020',],axis=1)\n",
    "target = data['Yield (Bales/Hectare)']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dedc91e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score - Decision Tree: 0.7604411530207819\n",
      "R2 Score - Neural Network: 0.5879846977119166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chandu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree model and a Feedforward Neural Network\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "data=pd.read_excel(\"final catgry.xlsx\")\n",
    "x=data.drop('Yield (Bales/Hectare)',axis=1).values\n",
    "x\n",
    "y=data['Yield (Bales/Hectare)'].values\n",
    "y\n",
    "# Select relevant features and target variable\n",
    "features =data.drop(['Yield (Bales/Hectare)','Year_2014 - 2015', 'Year_2015 - 2016', 'Year_2016 - 2017','Year_2017 - 2018', 'Year_2018 - 2019', 'Year_2019 - 2020',],axis=1)\n",
    "target = data['Yield (Bales/Hectare)']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Decision Tree model\n",
    "decision_tree = DecisionTreeRegressor(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using Decision Tree\n",
    "y_pred_dt = decision_tree.predict(X_test)\n",
    "\n",
    "# Train a Feedforward Neural Network model\n",
    "neural_network = MLPRegressor(hidden_layer_sizes=(64, 64), activation='relu', random_state=42)\n",
    "neural_network.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using Neural Network\n",
    "y_pred_nn = neural_network.predict(X_test)\n",
    "\n",
    "# Evaluate the models\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "r2_nn = r2_score(y_test, y_pred_nn)\n",
    "\n",
    "print('R2 Score - Decision Tree:', r2_dt)\n",
    "print('R2 Score - Neural Network:', r2_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e68904d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.7771403698621082\n"
     ]
    }
   ],
   "source": [
    "#grnn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Load the data\n",
    "data=pd.read_excel(\"final catgry.xlsx\")\n",
    "x=data.drop('Yield (Bales/Hectare)',axis=1).values\n",
    "x\n",
    "y=data['Yield (Bales/Hectare)'].values\n",
    "y\n",
    "# Select relevant features and target variable\n",
    "features = x\n",
    "target = y\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calculate the sigma parameter (spread factor)\n",
    "sigma = np.std(X_train)\n",
    "\n",
    "# Calculate the activation for each training sample\n",
    "activations = np.exp(-np.square(distance.cdist(X_train, X_train) / (2 * sigma ** 2)))\n",
    "\n",
    "# Calculate the weights using the Moore-Penrose pseudoinverse\n",
    "weights = np.linalg.pinv(activations) @ y_train.reshape(-1, 1)\n",
    "\n",
    "# Make predictions on the test set\n",
    "activations_test = np.exp(-np.square(distance.cdist(X_test, X_train) / (2 * sigma ** 2)))\n",
    "y_pred = activations_test @ weights\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e397f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53971d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 1s 3ms/step - loss: 4058.7163\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 143.3092\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 19.4368\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 10.4175\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.1868\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.2355\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 6.3854\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.8636\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.4905\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.1899\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 4.9706\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 4.8197\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 4.5630\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 4.7391\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 4.4052\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 4.2215\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 4.0982\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 4.0122\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.8179\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.8953\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.7917\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.7551\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.8222\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.8079\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3.7518\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.4002\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.3687\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.3682\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.3472\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.3114\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.2215\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.1254\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3.2354\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.2855\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.9966\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.9310\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.9485\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.8974\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.2341\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.9312\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.7352\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.7063\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.5833\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.7794\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.8367\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.7879\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.4665\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.6163\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.6373\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.3679\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.3339\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.2723\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.2160\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.2435\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.2022\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.3852\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.2012\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.1412\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.1547\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.9768\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.2874\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.5393\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.0050\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.2180\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.0866\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.8054\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.7885\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.7666\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.8404\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.6588\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.7565\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.6499\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.6674\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.9002\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.6579\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.5374\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4797\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.5926\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.6548\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.4871\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.5333\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.4284\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.3870\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.3601\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.3932\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.2766\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.5703\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.5652\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.3827\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.8134\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.5337\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.1813\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.3879\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.6261\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.1482\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.6349\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.6422\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.2491\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.2181\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.1253\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "R2 Score: 0.6906907213002058\n"
     ]
    }
   ],
   "source": [
    "#backpropagation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "data=pd.read_excel(\"final catgry.xlsx\")\n",
    "x=data.drop('Yield (Bales/Hectare)',axis=1).values\n",
    "x\n",
    "y=data['Yield (Bales/Hectare)'].values\n",
    "y\n",
    "# Select relevant features and target variable\n",
    "features = x\n",
    "target = y\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert target variable to a numpy array\n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(60,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf26e502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.750043160408206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data=pd.read_excel(\"final catgry.xlsx\")\n",
    "x=data.drop('Yield (Bales/Hectare)',axis=1).values\n",
    "x\n",
    "y=data['Yield (Bales/Hectare)'].values\n",
    "y\n",
    "# Select relevant features and target variable\n",
    "features =data.drop(['Yield (Bales/Hectare)','Year_2014 - 2015', 'Year_2015 - 2016', 'Year_2016 - 2017','Year_2017 - 2018', 'Year_2018 - 2019', 'Year_2019 - 2020',],axis=1)\n",
    "target = data['Yield (Bales/Hectare)']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create AdaBoostRegressor model\n",
    "model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d75a00ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.8579825514864203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data=pd.read_excel(\"final catgry.xlsx\")\n",
    "x=data.drop('Yield (Bales/Hectare)',axis=1).values\n",
    "x\n",
    "y=data['Yield (Bales/Hectare)'].values\n",
    "y\n",
    "# Select relevant features and target variable\n",
    "features =data.drop(['Yield (Bales/Hectare)','Year_2014 - 2015', 'Year_2015 - 2016', 'Year_2016 - 2017','Year_2017 - 2018', 'Year_2018 - 2019', 'Year_2019 - 2020',],axis=1)\n",
    "target = data['Yield (Bales/Hectare)']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create BaggingRegressor model\n",
    "model = BaggingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d021e103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.855214050012718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data=pd.read_excel(\"final catgry.xlsx\")\n",
    "x=data.drop('Yield (Bales/Hectare)',axis=1).values\n",
    "x\n",
    "y=data['Yield (Bales/Hectare)'].values\n",
    "y\n",
    "# Select relevant features and target variable\n",
    "features =data.drop(['Yield (Bales/Hectare)','Year_2014 - 2015', 'Year_2015 - 2016', 'Year_2016 - 2017','Year_2017 - 2018', 'Year_2018 - 2019', 'Year_2019 - 2020',],axis=1)\n",
    "target = data['Yield (Bales/Hectare)']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create ExtraTreesRegressor model\n",
    "model = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56afffc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.8146928635594929\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data=pd.read_excel(\"final catgry.xlsx\")\n",
    "x=data.drop('Yield (Bales/Hectare)',axis=1).values\n",
    "x\n",
    "y=data['Yield (Bales/Hectare)'].values\n",
    "y\n",
    "# Select relevant features and target variable\n",
    "features =data.drop(['Yield (Bales/Hectare)','Year_2014 - 2015', 'Year_2015 - 2016', 'Year_2016 - 2017','Year_2017 - 2018', 'Year_2018 - 2019', 'Year_2019 - 2020',],axis=1)\n",
    "target = data['Yield (Bales/Hectare)']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create individual regression models\n",
    "model1 = LinearRegression()\n",
    "model2 = DecisionTreeRegressor()\n",
    "model3 = KNeighborsRegressor()\n",
    "\n",
    "# Create VotingRegressor model\n",
    "model = VotingRegressor([('linear', model1), ('tree', model2), ('knn', model3)])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d485022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.860963035244939\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "\n",
    "\n",
    "# Select relevant features and target variable\n",
    "features =data.drop(['Yield (Bales/Hectare)','Year_2014 - 2015', 'Year_2015 - 2016', 'Year_2016 - 2017','Year_2017 - 2018', 'Year_2018 - 2019', 'Year_2019 - 2020',],axis=1)\n",
    "target = data['Yield (Bales/Hectare)']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using Random Forest\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c1771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
