{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c489ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9db6db0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "56/56 [==============================] - 2s 4ms/step - loss: 6.8389\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.8878\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.8265\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.8612\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 3.7922\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.8167\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 3.7704\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.7839\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.7929\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.8232\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.7595\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 3.7252\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.7384\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.7689\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.7172\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.6769\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.6675\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.6607\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.6411\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.7749\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 3.6074\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.6198\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.5837\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.5967\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 3.5847\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 3.5660\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 3.5590\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 3.5114\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 3.5146\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 3.5559\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 3.5593\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 3.4239\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 3.4560\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 3.3987\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 3.4060\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 3.3932\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 3.3767\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 3.4111\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 3.4079\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 3.3161\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 3.2963\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 3.2442\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 3.2632\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 3.1995\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 3.2290\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 3.2554\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 3.1868\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 3.2714\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 3.1618\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 3.1107\n",
      "Test Loss: 3.558763027191162\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import r2_score\n",
    "# Load the data\n",
    "data=pd.read_excel(\"final catgry.xlsx\")\n",
    "\n",
    "# Select relevant features and target variable\n",
    "features = ['Rainfall(mm)', 'Minimum Temparature(C)', 'Maximum Temperature (C)', 'Ph', 'N(Kg/Hectar)', 'P(Kg/Hectar)', 'K(Kg/Hectar)', 'Zn(ppm)', 'Fe(ppm)', 'Cu(ppm)', 'Mn(ppm)', 'Irrigation(MBGL)']\n",
    "target = 'Yield (Bales/Hectare)'\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features using Min-Max normalization\n",
    "scaler = MinMaxScaler()\n",
    "train_data[features] = scaler.fit_transform(train_data[features])\n",
    "test_data[features] = scaler.transform(test_data[features])\n",
    "\n",
    "# Prepare the sequences\n",
    "sequence_length = 5  # Number of past observations to consider\n",
    "X_train, y_train = [], []\n",
    "for i in range(sequence_length, len(train_data)):\n",
    "    X_train.append(train_data[features].values[i - sequence_length:i])\n",
    "    y_train.append(train_data[target].values[i])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "X_test, y_test = [], []\n",
    "for i in range(sequence_length, len(test_data)):\n",
    "    X_test.append(test_data[features].values[i - sequence_length:i])\n",
    "    y_test.append(test_data[target].values[i])\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "# Build the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(sequence_length, len(features))))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Loss:', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "065f7a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -0.03818859728962143\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "data=pd.read_excel(\"final catgry.xlsx\")\n",
    "\n",
    "# Select relevant features and target variable\n",
    "features = ['Rainfall(mm)', 'Minimum Temparature(C)', 'Maximum Temperature (C)', 'Ph', 'N(Kg/Hectar)', 'P(Kg/Hectar)', 'K(Kg/Hectar)', 'Zn(ppm)', 'Fe(ppm)', 'Cu(ppm)', 'Mn(ppm)', 'Irrigation(MBGL)']\n",
    "target = 'Yield (Bales/Hectare)'\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dd0c22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.04606231223295654\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "data=pd.read_excel(\"final catgry.xlsx\")\n",
    "x=data.drop('Yield (Bales/Hectare)',axis=1).values\n",
    "x\n",
    "y=data['Yield (Bales/Hectare)'].values\n",
    "y\n",
    "# Select relevant features and target variable\n",
    "features = x\n",
    "target = y\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the SVR model\n",
    "model = SVR(kernel='rbf')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3567e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.8726466507766351\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "data=pd.read_excel(\"final catgry.xlsx\")\n",
    "x=data.drop('Yield (Bales/Hectare)',axis=1).values\n",
    "x\n",
    "y=data['Yield (Bales/Hectare)'].values\n",
    "y\n",
    "# Select relevant features and target variable\n",
    "features = x\n",
    "target = y\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ace8870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 1s 3ms/step - loss: 5.3907\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.6641\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.6807\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.0670\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.7526\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.6227\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5447\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4728\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4232\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3854\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3517\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3304\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2987\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2770\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2623\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2474\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2311\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2097\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1980\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1882\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1810\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1652\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1626\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1497\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1488\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1393\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1331\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1272\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1155\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1104\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1111\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1006\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0988\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0961\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0862\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0823\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0796\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0788\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0733\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0676\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0630\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0597\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0610\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0575\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0517\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0495\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0461\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0462\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0425\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0441\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0389\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0374\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0356\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0326\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0306\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0306\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0276\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0284\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0264\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0227\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0238\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0230\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0218\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0196\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0174\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0176\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0120\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0079\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0075\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0062\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0051\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0054\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0052\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0050\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0043\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0034\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0032\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0029\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "R2 Score: 0.8216029340260037\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "data=pd.read_excel(\"final catgry.xlsx\")\n",
    "x=data.drop('Yield (Bales/Hectare)',axis=1).values\n",
    "x\n",
    "y=data['Yield (Bales/Hectare)'].values\n",
    "y\n",
    "# Select relevant features and target variable\n",
    "features = x\n",
    "target = y\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dedc91e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score - Decision Tree: 0.7741166515414697\n",
      "R2 Score - Neural Network: 0.4022933056051119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chandu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "data=pd.read_excel(\"final catgry.xlsx\")\n",
    "x=data.drop('Yield (Bales/Hectare)',axis=1).values\n",
    "x\n",
    "y=data['Yield (Bales/Hectare)'].values\n",
    "y\n",
    "# Select relevant features and target variable\n",
    "features = x\n",
    "target = y\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Decision Tree model\n",
    "decision_tree = DecisionTreeRegressor(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using Decision Tree\n",
    "y_pred_dt = decision_tree.predict(X_test)\n",
    "\n",
    "# Train a Feedforward Neural Network model\n",
    "neural_network = MLPRegressor(hidden_layer_sizes=(64, 64), activation='relu', random_state=42)\n",
    "neural_network.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using Neural Network\n",
    "y_pred_nn = neural_network.predict(X_test)\n",
    "\n",
    "# Evaluate the models\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "r2_nn = r2_score(y_test, y_pred_nn)\n",
    "\n",
    "print('R2 Score - Decision Tree:', r2_dt)\n",
    "print('R2 Score - Neural Network:', r2_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51c7a77f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neurolab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mneurolab\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnl\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'neurolab'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neurolab as nl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('your_data.csv')\n",
    "x=data.drop('Yield (Bales/Hectare)',axis=1).values\n",
    "x\n",
    "y=data['Yield (Bales/Hectare)'].values\n",
    "y\n",
    "# Select relevant features and target variable\n",
    "features = x\n",
    "target = y\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the GRNN model\n",
    "input_size = len(features)\n",
    "output_size = 1\n",
    "grnn = nl.net.newgrnn(np.array(X_train), np.array(y_train).reshape(-1, 1))\n",
    "\n",
    "# Train the GRNN model\n",
    "grnn.train(np.array(X_train), np.array(y_train).reshape(-1, 1))\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = grnn.sim(np.array(X_test))\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
